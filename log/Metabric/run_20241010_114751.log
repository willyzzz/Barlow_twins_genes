2024-10-10 11:47:51,604 - INFO - Using device: cuda
2024-10-10 11:47:51,605 - INFO - Stage 1: Loading data...
2024-10-10 12:11:42,683 - INFO - Number of classes: 5
2024-10-10 12:11:42,683 - INFO - Stage 2: Initializing models...
2024-10-10 12:11:42,701 - INFO - Configuration Parameters:
2024-10-10 12:11:42,702 - INFO - seed: 42
2024-10-10 12:11:42,702 - INFO - batchsize: 128
2024-10-10 12:11:42,702 - INFO - sample_size: 1000
2024-10-10 12:11:42,702 - INFO - lambda_noise: 0.1
2024-10-10 12:11:42,702 - INFO - variance_threshold: 0.9
2024-10-10 12:11:42,702 - INFO - output_dim: 64
2024-10-10 12:11:42,702 - INFO - hidden_dim: 256
2024-10-10 12:11:42,702 - INFO - project_dim: 256
2024-10-10 12:11:42,702 - INFO - mlp_hidden_dim: 64
2024-10-10 12:11:42,702 - INFO - learning_rate: 0.0001
2024-10-10 12:11:42,702 - INFO - weight_decay: 0.001
2024-10-10 12:11:42,702 - INFO - num_epochs: 5000
2024-10-10 12:11:42,702 - INFO - mlp_epochs: 5000
2024-10-10 12:11:42,702 - INFO - loss_lambda_param: 0.005
2024-10-10 12:11:42,702 - INFO - scaling_method: minmax
2024-10-10 12:11:42,702 - INFO - eval_metric: survival
2024-10-10 12:11:42,702 - INFO - model_save_path: ./model_checkpoints
2024-10-10 12:11:42,702 - INFO - fra_save_path: ./fra_pre
2024-10-10 12:11:42,702 - INFO - training_dataset_name: All
2024-10-10 12:11:42,702 - INFO - testing_dataset_name: Metabric
2024-10-10 12:11:42,702 - INFO - device: cuda
2024-10-10 12:11:42,702 - INFO - sc_path: ../cancer_single_cell_data/processed_data_5000.h5ad
2024-10-10 12:11:42,702 - INFO - bulk_path: ../cancer_brca_metabric_bulk_data/data_mrna_illumina_microarray_zscores_ref_diploid_samples.txt
2024-10-10 12:11:42,702 - INFO - stage_path: ../cancer_brca_metabric_bulk_data/Tumor_Stage.txt
2024-10-10 12:11:42,702 - INFO - survival_path: ../Synapse_metabric/Clinical_Overall_Survival_Data_from_METABRIC.txt
2024-10-10 12:11:42,702 - INFO - Model Architectures:
2024-10-10 12:11:42,703 - INFO - Encoder: GeneResNetEncoder(
  (initial_layer): Sequential(
    (0): Linear(in_features=2565, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (layer1): Sequential(
    (0): GeneResNetBlock(
      (fc1): Linear(in_features=512, out_features=128, bias=True)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc2): Linear(in_features=128, out_features=128, bias=True)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc3): Linear(in_features=128, out_features=512, bias=True)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): GeneResNetBlock(
      (fc1): Linear(in_features=512, out_features=128, bias=True)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc2): Linear(in_features=128, out_features=128, bias=True)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc3): Linear(in_features=128, out_features=512, bias=True)
      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): GeneResNetBlock(
      (fc1): Linear(in_features=512, out_features=64, bias=True)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc2): Linear(in_features=64, out_features=64, bias=True)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc3): Linear(in_features=64, out_features=256, bias=True)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): GeneResNetBlock(
      (fc1): Linear(in_features=256, out_features=64, bias=True)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc2): Linear(in_features=64, out_features=64, bias=True)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc3): Linear(in_features=64, out_features=256, bias=True)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): GeneResNetBlock(
      (fc1): Linear(in_features=256, out_features=32, bias=True)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc2): Linear(in_features=32, out_features=32, bias=True)
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc3): Linear(in_features=32, out_features=128, bias=True)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Linear(in_features=256, out_features=128, bias=True)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): GeneResNetBlock(
      (fc1): Linear(in_features=128, out_features=32, bias=True)
      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc2): Linear(in_features=32, out_features=32, bias=True)
      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc3): Linear(in_features=32, out_features=128, bias=True)
      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (fc): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
2024-10-10 12:11:42,703 - INFO - Projector: Projector(
  (layers): Sequential(
    (0): Linear(in_features=64, out_features=256, bias=False)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=256, out_features=256, bias=False)
    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=256, out_features=256, bias=False)
    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
)
2024-10-10 12:11:42,703 - INFO - MLP Bulk: MLPClassifier(
  (layers): Sequential(
    (0): Linear(in_features=2565, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=5, bias=True)
  )
)
2024-10-10 12:11:42,703 - INFO - MLP Embedded: MLPClassifier(
  (layers): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=5, bias=True)
  )
)
2024-10-10 12:11:42,703 - INFO - Stage 3: Training Barlow Twins...
2024-10-10 12:12:37,169 - INFO - Epoch 100 completed. Loss: 3.1392
2024-10-10 12:13:35,143 - INFO - Epoch 200 completed. Loss: 2.9389
2024-10-10 12:14:34,622 - INFO - Epoch 300 completed. Loss: 2.8452
2024-10-10 12:15:31,561 - INFO - Epoch 400 completed. Loss: 2.7825
2024-10-10 12:16:27,088 - INFO - Epoch 500 completed. Loss: 2.7364
2024-10-10 12:17:24,768 - INFO - Epoch 600 completed. Loss: 2.7288
2024-10-10 12:18:19,147 - INFO - Epoch 700 completed. Loss: 2.6888
2024-10-10 12:19:16,953 - INFO - Epoch 800 completed. Loss: 2.6499
2024-10-10 12:20:17,066 - INFO - Epoch 900 completed. Loss: 2.6272
2024-10-10 12:21:06,334 - INFO - Epoch 1000 completed. Loss: 2.6129
2024-10-10 12:22:01,107 - INFO - Epoch 1100 completed. Loss: 2.5923
2024-10-10 12:22:55,219 - INFO - Epoch 1200 completed. Loss: 2.5835
2024-10-10 12:23:53,352 - INFO - Epoch 1300 completed. Loss: 2.5491
2024-10-10 12:24:54,146 - INFO - Epoch 1400 completed. Loss: 2.5378
2024-10-10 12:25:49,789 - INFO - Epoch 1500 completed. Loss: 2.5073
2024-10-10 12:26:46,614 - INFO - Epoch 1600 completed. Loss: 2.5157
2024-10-10 12:27:47,046 - INFO - Epoch 1700 completed. Loss: 2.4647
2024-10-10 12:28:42,497 - INFO - Epoch 1800 completed. Loss: 2.4807
2024-10-10 12:29:40,145 - INFO - Epoch 1900 completed. Loss: 2.4490
2024-10-10 12:30:36,197 - INFO - Epoch 2000 completed. Loss: 2.4551
2024-10-10 12:31:37,694 - INFO - Epoch 2100 completed. Loss: 2.4413
2024-10-10 12:32:38,522 - INFO - Epoch 2200 completed. Loss: 2.4297
2024-10-10 12:33:40,292 - INFO - Epoch 2300 completed. Loss: 2.4166
2024-10-10 12:34:32,402 - INFO - Epoch 2400 completed. Loss: 2.3923
2024-10-10 12:35:30,741 - INFO - Epoch 2500 completed. Loss: 2.3750
2024-10-10 12:36:25,597 - INFO - Epoch 2600 completed. Loss: 2.3663
2024-10-10 12:37:22,193 - INFO - Epoch 2700 completed. Loss: 2.3471
2024-10-10 12:38:19,174 - INFO - Epoch 2800 completed. Loss: 2.3444
2024-10-10 12:39:16,637 - INFO - Epoch 2900 completed. Loss: 2.3157
2024-10-10 12:40:17,368 - INFO - Epoch 3000 completed. Loss: 2.2994
2024-10-10 12:41:12,781 - INFO - Epoch 3100 completed. Loss: 2.2840
2024-10-10 12:42:05,633 - INFO - Epoch 3200 completed. Loss: 2.2651
2024-10-10 12:43:04,397 - INFO - Epoch 3300 completed. Loss: 2.2444
2024-10-10 12:44:00,871 - INFO - Epoch 3400 completed. Loss: 2.2355
2024-10-10 12:44:58,547 - INFO - Epoch 3500 completed. Loss: 2.2319
2024-10-10 12:45:54,086 - INFO - Epoch 3600 completed. Loss: 2.2021
2024-10-10 12:46:52,902 - INFO - Epoch 3700 completed. Loss: 2.2071
2024-10-10 12:47:55,201 - INFO - Epoch 3800 completed. Loss: 2.1830
2024-10-10 12:48:50,513 - INFO - Epoch 3900 completed. Loss: 2.1694
2024-10-10 12:49:45,716 - INFO - Epoch 4000 completed. Loss: 2.1836
2024-10-10 12:50:39,962 - INFO - Epoch 4100 completed. Loss: 2.1380
2024-10-10 12:51:34,449 - INFO - Epoch 4200 completed. Loss: 2.1467
2024-10-10 12:52:29,349 - INFO - Epoch 4300 completed. Loss: 2.1228
2024-10-10 12:53:21,886 - INFO - Epoch 4400 completed. Loss: 2.1467
2024-10-10 12:54:17,871 - INFO - Epoch 4500 completed. Loss: 2.1187
2024-10-10 12:55:11,901 - INFO - Epoch 4600 completed. Loss: 2.1077
2024-10-10 12:56:04,278 - INFO - Epoch 4700 completed. Loss: 2.0861
2024-10-10 12:56:58,299 - INFO - Epoch 4800 completed. Loss: 2.0792
2024-10-10 12:57:58,411 - INFO - Epoch 4900 completed. Loss: 2.0811
2024-10-10 12:58:55,055 - INFO - Epoch 5000 completed. Loss: 2.0560
2024-10-10 12:58:55,055 - INFO - Stage 4: Preparing data for classification...
2024-10-10 12:58:55,059 - INFO - Stage 5: Generating Barlow Twins embeddings...
2024-10-10 12:58:55,239 - INFO - Bulk tensor saved to ../result/Metabric_20241010_114751/bulk_tensor.pt
2024-10-10 12:58:55,239 - INFO - Embeddings saved to ../result/Metabric_20241010_114751/embedding.pt
2024-10-10 12:58:55,239 - INFO - All stages completed.
